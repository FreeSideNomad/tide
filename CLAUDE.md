# Claude Code Notes

## Project Info

**Tide** is a Python Flet application targeting mobile and web users. This is a safety-first DBT (Dialectical Behavior Therapy) AI assistant designed to guide individuals through DBT skills development using structured decision-tree architecture rather than open-ended chat.

### Technology Stack
- **Python Flet**: Cross-platform framework for mobile and web deployment
- **Target Platforms**: Mobile (iOS/Android) and web browsers prioritizing mobile-first design
- **Architecture**: Safety-constrained decision trees with NLP enhancement for personalization
- **Decision Tree Implementation**: JSON structure with rule engine for crisis detection and skill selection
- **üîê AUTHENTICATION REQUIREMENT**: **MANDATORY** - All authentication MUST follow Flet's official cookbook at https://flet.dev/docs/cookbook/authentication/ - NO custom authentication solutions allowed


### Core Features
- **Evidence-based DBT skill delivery** through structured decision pathways (not chat)
- **Four DBT modules**: Mindfulness, Distress Tolerance, Emotion Regulation, Interpersonal Effectiveness
- **Safety-first design** prioritizing user wellbeing over engagement metrics or feature completeness
- **Structured decision trees** with predetermined safe pathways and NLP personalization
- **Crisis survival skills** focus with immediate safety plan activation for 8+ intensity or crisis keywords
- **Human oversight integration** with seamless handoff protocols for flagged situations

## Wiki Documentation

The project wiki is integrated as a git submodule at `docs/wiki/`. This provides direct access to all wiki content within the repository.

### Wiki Workflow

**üìñ See [WIKI_WORKFLOW.md](WIKI_WORKFLOW.md) for complete documentation on working with wiki content.**

#### Quick Reference:
- **Get latest wiki changes**: `git submodule update --remote docs/wiki`
- **Commit wiki changes**: `cd docs/wiki && git add . && git commit -m "message" && git push origin master`
- **Update main repo reference**: `git add docs/wiki && git commit -m "docs: update wiki submodule" && git push origin main`

### Wiki Files

Wiki content is directly accessible in the `docs/wiki/` directory:
- `docs/wiki/vision.md` - Complete project vision and business requirements
- `docs/wiki/dbt-ai-assistant-brainstorm.md` - Design decisions and technical brainstorming
- `docs/wiki/canadian-mental-health-ai-regulatory-framework.md` - Canadian legal and ethical considerations
- `docs/wiki/dbt-distress-tolerance-tree.md` - Detailed distress tolerance decision tree architecture

### Target Users (from docs/wiki/vision.md)

**Primary Users:**
1. Individuals seeking DBT skills without access to therapy
2. Crisis prevention users needing evidence-based techniques during distress
3. Skill practice users supplementing existing therapy
4. Self-help seekers building emotional regulation and interpersonal skills

**Secondary Users:**
1. Mental health professionals referencing the tool as therapy supplement
2. Human advisors providing oversight and escalation support
3. Crisis counselors receiving escalated cases
4. Researchers studying AI-assisted skill development

### Key Business Requirements (from docs/wiki/vision.md)
- **BR-1**: Safety-First Architecture - Crisis detection with human escalation protocols
- **BR-2**: Evidence-Based DBT Skill Delivery - Structured decision trees only, no open-ended chat
- **BR-3**: Human Oversight Integration - 24/7 advisor availability for critical situations
- **BR-4**: Transparent AI Limitations - Clear disclaimers about therapy replacement boundaries
- **BR-5**: Crisis Detection and Response - Multi-layered safety systems with immediate escalation
- **BR-6**: Structured Decision Architecture - Predetermined pathways within safety constraints

### Safety-First Design Principles (from docs/wiki/dbt-ai-assistant-brainstorm.md)
- **Decision tree primary architecture** with NLP enhancement for personalization only
- **Standalone tool** for users without therapy access
- **Safety plan integration** required during registration before any skill access
- **No direct counseling** - guides to pre-established user resources
- **Crisis survival skills** focus with safety plan activation protocols
- **Maladaptive pattern detection** using keyword matching ("always", "never", "everyone", "no one")
- **Fact vs. perception awareness** - distinguish objective circumstances from emotional interpretations

### Clinical Evidence Base (from docs/wiki/dbt-ai-assistant-brainstorm.md)
- **8 high-quality RCTs** confirm DBT effectiveness
- **Low dropout rate** (27.3%) with moderate effect sizes
- **DBT skills are key mechanism** of change for suicide attempts, NSSI, depression, anger
- **Stand-alone training** growing evidence for transdiagnostic treatment
- **Safety planning reduces** suicidal behavior risk by 45%

### Canadian Regulatory Context (from docs/wiki/canadian-mental-health-ai-regulatory-framework.md)
- **PIPEDA compliance** required for mental health data handling
- **Provincial health information acts** apply across different provinces
- **Bill C-27/AIDA** (proposed) classifies crisis detection as high-impact AI system
- **Health Canada SaMD** classification considerations for crisis features
- **Indigenous data sovereignty** and cultural adaptation requirements
- **Ethical framework alignment** with Canadian AI Ethics Guidelines

The wiki repository URL: https://github.com/FreeSideNomad/tide/wiki

## Critical Development Process

**üö® MANDATORY: NO CODE WITHOUT EXPLICIT STAKEHOLDER APPROVAL**

### Security Decision Authority

**CRITICAL**: Claude Code is **PROHIBITED** from making security or architecture decisions independently. All security-impacting decisions require:

1. **ADR Process**: Architecture Decision Records (ADRs) via GitHub issues
2. **Stakeholder Approval**: Explicit approval from required stakeholders
3. **Implementation Block**: Features are BLOCKED until ADR approval

#### ADR-Required Decisions
- **Authentication & Authorization**: OAuth, session management, token storage
- **Data Protection**: Encryption, PII handling, healthcare data compliance
- **Architecture Changes**: Database design, API security, infrastructure
- **Safety Features**: Crisis detection, human oversight, emergency procedures
- **Third-Party Integrations**: Security-sensitive library selections

#### Implementation Rules
- ‚ùå **NO security decisions** without stakeholder consultation
- ‚ùå **NO architecture changes** without ADR approval
- ‚ùå **NO implementation** of security features without authorization
- ‚úÖ **ASK for clarification** when user stories lack security specifications
- ‚úÖ **CREATE ADRs** for all security and architecture decisions
- ‚úÖ **WAIT for approval** before implementing dependent features

**Current Blocking ADRs**:
- [ADR-0001 Token Storage](https://github.com/FreeSideNomad/tide/issues/13): OAuth token storage architecture - PENDING APPROVAL

### 4-Phase Development Workflow

**Phase 1: Planning & Collaboration**
1. Collaborate on .md files (documentation and requirements)
2. **Security Review**: Identify any security/architecture decisions needed
3. **Create ADRs**: For security/architecture decisions via GitHub issues
4. **Stakeholder Review**: Wait for explicit approval on .md files AND ADRs
5. **Wait for approval** before proceeding

**Phase 2: Issue Creation**
4. Create GitHub Issues (Epic, Feature, User Story) based on approved .md files
5. **Link to ADRs**: Reference approved ADRs in implementation issues
6. Issue-driven development approach

**Phase 3: Implementation Cycle (Per User Story)**
6. **Verify ADR Approval**: Ensure all dependent ADRs are approved
7. **Get explicit approval** for each user story before starting
8. Create feature branch for specific user story
9. **Implement per ADR requirements**: Follow approved architecture decisions
10. Implement & test until all tests pass
11. Commit & merge to remote main, fix build issues

**Phase 4: Validation & Iteration**
12. Stakeholder manual testing
13. **Security validation**: Verify ADR compliance
14. Create GitHub issues for problems found
15. Fix & merge code
16. Repeat until user story complete
17. Move to next user story only after completion

### Essential Rules
- ‚úÖ Collaborate on .md files freely
- ‚úÖ **Create ADRs** for security/architecture decisions
- ‚úÖ **Ask for clarification** on incomplete requirements
- ‚ùå **Never make security decisions** without stakeholder consultation
- ‚ùå Never implement code without explicit stakeholder approval
- ‚ùå **Never implement features** dependent on unapproved ADRs
- ‚ùå Never create GitHub issues without approved requirements
- ‚ùå Never merge code without passing tests and build validation

### ADR (Architecture Decision Record) Process

**Location**: All ADRs created as GitHub issues using the "ADR - Architecture Decision Record" issue template

**Required Stakeholders** (per ADR):
- **Product Owner**: Business requirements and user impact
- **Technical Lead**: Technical architecture review
- **Security Reviewer**: Security implications assessment
- **Compliance Reviewer**: Healthcare/privacy compliance (if applicable)

**ADR Workflow**:
1. **Identify Decision**: Security or architecture decision needed
2. **Create GitHub Issue**: Use ADR template, assign stakeholders
3. **Stakeholder Review**: Discussion via issue comments
4. **Approval**: All required stakeholders must approve
5. **Implementation**: Proceed only after issue closed as "Accepted"

**ADR Examples**:
- [ADR-0001 Token Storage Architecture](https://github.com/FreeSideNomad/tide/issues/13)
- Authentication provider selection
- Database security configurations
- API encryption requirements
- Session management approaches

See detailed process: [docs/STAKEHOLDER_APPROVAL_PROCESS.md](/docs/STAKEHOLDER_APPROVAL_PROCESS.md)

## Technology Stack

### Approved Technologies
- **Frontend**: Python Flet for cross-platform mobile and web deployment
- **Database**: PostgreSQL with pgvector for RAG storage
- **ORM**: SQLAlchemy for maintainability and type safety
- **Session Management**: Follow Flet authentication cookbook session patterns
- **AI Integration**: OpenAI API with cost management
- **Authentication**: **MANDATORY** Flet official authentication patterns from https://flet.dev/docs/cookbook/authentication/ (OAuth providers: Google, Microsoft, GitHub, etc.)
- **Package Management**: uv for fast Python dependency management
- **Testing**: Pytest with comprehensive test suite (unit, integration, E2E)
- **Code Quality**: Black (formatting), Ruff (linting), Safety (security), Bandit (security)
- **Browser Testing**: Selenium and Playwright for E2E automation
- **Containerization**: Docker and Docker Compose for development and testing
- **CI/CD**: GitHub Actions with comprehensive pipeline
- **Development Automation**: Makefile and shell scripts for workflow automation
- **Git Integration**: Pre-commit hooks for quality gates
- **Deployment**: GitHub Actions + cloud provider

### Technology Guidelines
1. **Simplicity over sophistication** - choose boring, proven technologies
2. **GitHub integration** - prioritize tools that work well with GitHub
3. **User experience** - optimize for end-user productivity
4. **Testing support** - ensure technologies support automated testing
5. **AI integration** - consider how well tools work with LLM APIs

## Domain Model

The application follows Domain-Driven Design (DDD) principles with a comprehensive domain model that serves as the foundation for all implementation work. The domain model establishes ubiquitous language and bounded contexts used across all epics, features, and user stories.

**Domain Model Location**: `docs/wiki/domain-model.md`

### Domain-Driven Design Approach
- **Bounded Contexts**: User Management, Questionnaire, DBT Skills (future), Safety (future)
- **Aggregate Design**: User aggregate owns responses; Question aggregate manages questionnaire structure
- **Ubiquitous Language**: All team communication uses domain model terminology
- **Domain Events**: Track important business events across aggregate boundaries
- **Repository Pattern**: Encapsulates data access and maintains domain integrity

### Key Domain Principles
- **User-Centric Design**: User aggregate is the primary root containing responses and preferences
- **Flexible Questionnaire**: Single questionnaire with deprecated/active questions rather than versioning
- **Session Separation**: Authentication tokens and temporary state stored in Redis, not domain model
- **Eventual Consistency**: New questions automatically become pending for all existing users

### Authentication Architecture
- **Flet Official Authentication**: **MANDATORY** - Application MUST follow https://flet.dev/docs/cookbook/authentication/ - no custom solutions allowed
- **OAuth Integration**: Use Flet's official OAuth providers (Google, Microsoft, GitHub, etc.) as documented in cookbook
- **Session Management**: Follow Flet's session handling patterns and best practices from cookbook
- **Route Protection**: Implement authentication guards using Flet's recommended patterns
- **User State Management**: Use Flet's user session and state management as outlined in cookbook
- **Security Standards**: Adhere to all security recommendations in Flet authentication cookbook

## GitHub Project Management

### Custom Issue Types and Templates

The project uses GitHub Issues with custom labels and templates to track work according to our domain-driven approach. All issues must reference relevant wiki documentation to ensure complete traceability from business requirements to implementation.

#### Issue Type: Epic
**Purpose**: High-level business capability spanning multiple features
**Label**: `type:epic`
**Template**:
```markdown
# Epic: [Epic Name]

## Overview
[Brief description of business capability]

## Wiki References
- Epic Documentation: `docs/wiki/epic-[name]/epic-[name].md`
- Domain Model: `docs/wiki/domain-model.md` (relevant bounded contexts)
- Business Requirements: Reference to BR-XXX from vision.md

## Business Context
[Business problem this epic solves]

## Target Users
- Primary: [user types from domain model]
- Secondary: [user types from domain model]

## Features
- [ ] Feature 1: [Name] (links to feature issues)
- [ ] Feature 2: [Name] (links to feature issues)

## Success Metrics
- [Measurable outcomes]

## Dependencies
- [Other epics, external systems]

## Definition of Done
- [ ] All features completed and tested
- [ ] Domain events implemented
- [ ] Wiki documentation updated
- [ ] Acceptance criteria met
```

#### Issue Type: Feature
**Purpose**: Specific functionality within an epic
**Label**: `type:feature`
**Template**:
```markdown
# Feature: [Feature Name]

## Overview
[Brief description of feature functionality]

## Wiki References
- Feature Documentation: `docs/wiki/epic-[name]/feature-[number]-[name].md`
- Domain Model: `docs/wiki/domain-model.md` (relevant aggregates/services)
- Epic: [Link to parent epic issue]

## Domain Model Integration
### Bounded Context
[User Management, Questionnaire, etc.]

### Domain Objects Used
- Aggregate Roots: [List from domain model]
- Entities: [List from domain model]
- Value Objects: [List from domain model]
- Domain Services: [List from domain model]

### Domain Events
- [List events this feature publishes/subscribes to]

## Essential Use Cases
[Reference use cases from feature documentation]

## User Stories
- [ ] Story 1: [Name] (links to user story issues)
- [ ] Story 2: [Name] (links to user story issues)

## Technical Requirements
- [Database changes, API requirements, etc.]

## Acceptance Criteria
- [ ] [Criteria from feature documentation]

## Dependencies
- [Other features, external services]

## Definition of Done
- [ ] All user stories completed
- [ ] Domain model implemented correctly
- [ ] Tests passing (unit, integration)
- [ ] Documentation updated
```

#### Issue Type: User Story
**Purpose**: Specific user need with acceptance criteria
**Label**: `type:user-story`
**Template**:
```markdown
# User Story: [Story Title]

## Story
**As a** [user type from domain model]
**I want** [goal/need]
**So that** [benefit/value]

## Wiki References
- Feature Documentation: `docs/wiki/epic-[name]/feature-[number]-[name].md`
- Essential Use Case: [Reference specific use case this story implements]
- Domain Model: `docs/wiki/domain-model.md`

## Feature Context
**Parent Feature**: [Link to feature issue]
**Epic**: [Link to epic issue]

## Domain Model Alignment
### Aggregates Involved
- [List relevant aggregates from domain model]

### Domain Services
- [List services this story uses]

### Domain Events
- [Events triggered by this story]

## Acceptance Criteria
[Detailed criteria from feature documentation]
- [ ] [Criterion 1]
- [ ] [Criterion 2]

## Technical Implementation Notes
- [Any specific technical considerations]
- [Database schema changes]
- [API endpoints affected]

## Testing Requirements
- [ ] Unit tests for business logic
- [ ] Integration tests for domain interactions
- [ ] End-to-end tests for user workflow

## Definition of Done
- [ ] Acceptance criteria met
- [ ] Code reviewed and approved
- [ ] Tests passing
- [ ] Domain model integrity maintained
- [ ] Documentation updated
```

#### Issue Type: Technical Task
**Purpose**: Infrastructure/technical work without direct user value
**Label**: `type:technical-task`
**Template**:
```markdown
# Technical Task: [Task Name]

## Overview
[Description of technical work needed]

## Wiki References
- Domain Model: `docs/wiki/domain-model.md` (if relevant)
- CLAUDE.md: [Reference relevant sections]

## Context
**Related Epic/Feature**: [Link if applicable]
**Business Justification**: [Why this technical work is needed]

## Technical Requirements
- [Specific technical deliverables]
- [Infrastructure changes]
- [Configuration updates]

## Dependencies
- [Other technical tasks, external systems]

## Acceptance Criteria
- [ ] [Technical criterion 1]
- [ ] [Technical criterion 2]

## Testing Requirements
- [ ] [How to verify the work is complete]

## Definition of Done
- [ ] Technical implementation complete
- [ ] Documentation updated
- [ ] No regressions introduced
- [ ] Code reviewed and approved
```

#### Issue Type: Spike
**Purpose**: Time-boxed research and investigation
**Label**: `type:spike`
**Template**:
```markdown
# Spike: [Research Topic]

## Research Questions
[What we need to investigate]

## Wiki References
- Domain Model: `docs/wiki/domain-model.md` (if relevant)
- Related Documentation: [Any relevant wiki pages]

## Context
**Related Epic/Feature**: [Link if applicable]
**Business Need**: [Why this research is important]

## Time-box
**Duration**: [Maximum time to spend]
**Deadline**: [When decision needed]

## Success Criteria
[How we'll know the spike is complete]
- [ ] [Research question 1 answered]
- [ ] [Research question 2 answered]

## Deliverables
- [ ] Research findings documented
- [ ] Recommendation provided
- [ ] Next steps identified
- [ ] Update relevant wiki documentation

## Potential Solutions to Explore
1. [Option 1]
2. [Option 2]
3. [Option 3]

## Definition of Done
- [ ] Research complete within time-box
- [ ] Findings documented
- [ ] Recommendation made
- [ ] Follow-up issues created if needed
```

#### Issue Type: Bug
**Purpose**: Defects in existing functionality
**Label**: `type:bug`
**Template**:
```markdown
# Bug: [Brief Description]

## Description
[Clear description of the issue]

## Steps to Reproduce
1. [Step 1]
2. [Step 2]
3. [Step 3]

## Expected Behavior
[What should happen]

## Actual Behavior
[What actually happens]

## Environment
- **Browser/Platform**: [Browser version, OS, mobile device]
- **User Type**: [From domain model - which user type affected]
- **Feature Area**: [Which feature/epic this affects]

## Domain Model Impact
**Affected Aggregates**: [User, Question, etc.]
**Affected Services**: [UserService, AuthenticationService, etc.]

## Severity
- [ ] Critical (blocks core functionality)
- [ ] High (major feature broken)
- [ ] Medium (feature partially broken)
- [ ] Low (minor issue)

## Related Issues
**Epic**: [Link if relevant]
**Feature**: [Link if relevant]
**User Stories**: [Links to affected stories]

## Definition of Done
- [ ] Root cause identified
- [ ] Fix implemented
- [ ] Tests added to prevent regression
- [ ] Code reviewed and approved
- [ ] Verified in all affected environments
```

### Kanban Board Setup

#### Board Structure
**Main Development Board**: Single kanban board tracking all work types

#### Columns
1. **Backlog** - Approved and ready for planning
2. **Ready** - Sized and ready to start (next sprint items)
3. **In Progress** - Currently being worked on
4. **Review** - Awaiting code review or stakeholder approval
5. **Testing** - In QA/testing phase
6. **Done** - Completed and verified

#### Swimlanes
- **Epic Level**: One swimlane per active epic
- **Bug Triage**: Separate swimlane for urgent bugs

#### Work In Progress (WIP) Limits
- **In Progress**: Maximum 3 items per developer
- **Review**: Maximum 5 items total
- **Testing**: Maximum 3 items total

#### Labels and Filtering
- **Type Labels**: `type:epic`, `type:feature`, `type:user-story`, `type:technical-task`, `type:spike`, `type:bug`
- **Priority Labels**: `priority:critical`, `priority:high`, `priority:medium`, `priority:low`
- **Epic Labels**: `epic:user-profile-setup`, `epic:dbt-skills`, etc.
- **Bounded Context Labels**: `context:user-management`, `context:questionnaire`, `context:dbt-skills`, `context:safety`

### Issue Workflow Rules

#### Epic ‚Üí Feature ‚Üí User Story Flow
1. **Epic** created first with complete wiki documentation
2. **Features** created and linked to Epic with domain model references
3. **User Stories** created and linked to Features with use case references
4. All issues must reference relevant wiki documentation
5. Domain model impact must be documented for all changes

#### Cross-Reference Requirements
- Every Feature must reference its Epic and domain model
- Every User Story must reference its Feature and essential use case
- Every implementation issue must trace back to business requirements
- All domain changes must be reflected in domain model documentation

## Remember

**"Every GitHub issue must be traceable to business value through our wiki documentation chain: Epic ‚Üí Feature ‚Üí User Story ‚Üí Essential Use Case ‚Üí Domain Model ‚Üí Business Requirements."**

Always ensure:
1. Complete wiki documentation before creating issues
2. Proper cross-referencing between issues and wiki
3. Domain model alignment documented in every issue
4. Acceptance criteria traced to business requirements
5. Clear definition of done for every work item

## Architecture Principles

### 1. Safety-First Architecture (Overrides All Other Principles)
- **User safety prioritized** over feature completeness, engagement, or technical elegance
- **Crisis detection algorithms** with immediate human escalation triggers
- **Evidence-based responses only** with clear citations and disclaimers
- **Fail-safe mechanisms** when AI confidence levels are insufficient
- **Complete audit trail** of all user interactions for safety monitoring
- **Multi-layer validation** before any AI-generated content reaches users

### 2. Domain-First Architecture
- **Core DBT business domain** comes first (Distress Tolerance MVP)
- Supporting domains (auth, user management) come later
- Start with **safety plan registration** before any skill access
- Define **crisis survival use cases** before technical infrastructure
- Defer authentication until **core safety features** are validated

### 3. GitHub-Native Development
- Use GitHub as single source of truth for all project artifacts
- Vision and context in GitHub Wiki
- Work tracking through GitHub Issues
- Project management via GitHub Projects
- Code in GitHub repositories
- Automation through GitHub Actions

### 4. User-Centric Validation
- Validate every significant decision with users before implementation
- Present plans as GitHub Issues for review
- Create UI mocks in structured format (Markdown/YAML) before coding
- Implement feedback loops at every stage
- **Prioritize user safety** over user experience preferences

### 5. Essential Use Cases Methodology
- Follow Alistair Cockburn's Essential Use Cases approach
- Start with essential user goals and intentions (crisis survival)
- Avoid technical implementation details initially
- Focus on "what" before "how"
- Progressive refinement through structured formats

### 6. Evidence-Based Content Management
- **All content sourced** from published DBT research and clinical guidelines
- **Version control** for all therapeutic content with clinical review requirements
- **Standardized response templates** based on validated interventions
- **Regular content audits** by qualified mental health professionals
- **Clear attribution** and citation for all therapeutic recommendations

## Database and Session Architecture

### PostgreSQL Setup
- **Primary Database**: PostgreSQL for all persistent domain data
- **Vector Storage**: pgvector extension for RAG capabilities
- **Conversation Storage**: Full conversation logging and context
- **ORM**: SQLAlchemy for database operations
- **Migrations**: Alembic for database schema management

### Session and State Management
- **Flet Authentication Patterns**: Follow Flet cookbook session management (https://flet.dev/docs/cookbook/authentication/)
- **Session Storage**: Use Flet's recommended session storage patterns
- **Authentication State**: Implement user authentication state using Flet's built-in mechanisms
- **Route Protection**: Use Flet's authentication guards and protected route patterns
- **Session Lifecycle**: Follow Flet's session management best practices
- **Caching Layer**: Application-level caching for frequently accessed data (if needed beyond Flet patterns)

### Data Storage Strategy
- **Persistent Domain Data**: User profiles, questionnaire responses, preferences in PostgreSQL
- **Session State**: Follow Flet authentication cookbook patterns for session and user state management
- **Conversational Data**: Full conversation logs in PostgreSQL tables
- **Vector Embeddings**: pgvector for similarity search and RAG capabilities
- **Document Storage**: GitHub wiki with version control, current versions in RAG vectors
- **Cache Strategy**: Application-level caching as needed, compatible with Flet authentication patterns

## Test-Driven Development (TDD) Requirements

### TDD Workflow (MANDATORY)
1. **Red Phase**: Write failing tests first that describe the desired behavior
2. **Green Phase**: Write minimal code to make tests pass
3. **Refactor Phase**: Improve code quality while maintaining passing tests
4. **Repeat**: Continue cycle for each new feature or bug fix

### TDD Implementation Rules
- **Tests First**: Always write tests before implementing functionality
- **One Failing Test**: Work on one failing test at a time
- **Minimal Implementation**: Write just enough code to pass the test
- **Comprehensive Coverage**: Ensure edge cases and error conditions are tested
- **Refactor Safely**: Only refactor when all tests are passing

### TDD for Different Test Types
- **Unit Tests**: Test individual functions, classes, and modules in isolation
- **Integration Tests**: Test component interactions and system boundaries
- **End-to-End Tests**: Test complete user workflows and system behavior

### TDD Benefits for Safety-Critical Application
- **Early Bug Detection**: Catch issues before they reach production
- **Regression Prevention**: Existing tests prevent breaking changes
- **Design Quality**: TDD encourages better API design and modularity
- **Documentation**: Tests serve as living documentation of system behavior
- **Confidence**: High test coverage enables safe refactoring and feature additions

## Quality Standards

### Code Quality
- **Test Coverage**: Minimum 90% for business logic with pytest unit and integration tests, 90% of code lines, branches
- **TDD Compliance**: All new features must follow TDD workflow (Red-Green-Refactor)
- **Code Review**: All changes require review via GitHub PR
- **Documentation**: Every public API documented
- **Performance**: Response times under 2 seconds for user interactions

### Development Quality
- **Linting**: Follow Python black formatting
- **Type Hints**: Use type annotations for better maintainability
- **Error Handling**: Comprehensive error handling and logging
- **Security**: Never expose secrets or API keys
- **Test-First Development**: Write tests before implementation code

## AI Integration Guidelines

### OpenAI API Usage
- **Cost Management**: Monitor token usage and implement rate limiting
- **Error Handling**: Graceful degradation when API unavailable
- **Context Management**: Efficient prompt engineering for cost control
- **Security**: Secure API key storage and usage patterns

### Conversation Management
- **Logging**: Full conversation audit trail in PostgreSQL
- **Context**: Dynamic context retrieval for relevant responses
- **Privacy**: Secure handling of conversation data
- **Performance**: Optimize for response time and user experience

## Common Pitfalls to Avoid

### Process Violations
1. **Skipping Vision/Requirements Phase**: Never implement without consulting essential use cases
2. **No UI Design Consultation**: Create mockups before any UI implementation
3. **Feature Creep**: Validate business need before adding features
4. **Violating Domain-First Principle**: Start with core business domain, not UI/infrastructure

### Technical Mistakes
1. **Premature Optimization**: Focus on working functionality first
2. **Over-Engineering**: Keep solutions simple and maintainable
3. **Ignoring Test Coverage**: Maintain quality standards from the start
4. **Security Oversights**: Follow security best practices consistently

## Safety-First Development Principles

**"Safety first, evidence-based, transparent limitations, with seamless human oversight."**

Always prioritize:
1. **User safety** over all other considerations (features, engagement, technical elegance)
2. **Evidence-based DBT content** over innovative but unvalidated approaches
3. **Crisis detection accuracy** over feature completeness
4. **Transparent AI limitations** over user engagement optimization
5. **Human oversight integration** over autonomous AI decision-making
6. **Structured decision pathways** over conversational AI flexibility

## Crisis Detection and Safety Requirements

### Crisis Detection Triggers
- **Intensity Level 8+** (on 1-10 scale) triggers safety plan activation
- **Crisis keywords** (self-harm, suicidal ideation) bypass normal flow
- **Maladaptive language patterns** ("always", "never", "everyone", "no one") flagged
- **System uncertainty** about appropriate skills triggers human escalation

### Safety Plan Integration
- **Required during registration** before accessing any skills
- **Rutgers DBT Adult Crisis Plan** template as foundation
- **Warning signs and coping strategies** required (minimum 1 and 3 respectively)
- **Support contacts** highly recommended but not blocking
- **Crisis activation** bypasses decision tree and goes directly to safety plan

### Clinical Validation Requirements
- Each decision point must reference **DBT literature**
- Skill recommendations must follow **evidence-based protocols**
- Crisis detection must meet **clinical safety standards**
- Coaching content must align with **DBT therapy principles**

## Distress Tolerance Module (MVP Focus)

### Core Skills (Evidence-Based)
- **TIPP**: Temperature, Intense Exercise, Paced Breathing, Paired Muscle Relaxation
- **STOP**: Stop, Take a step back, Observe, Proceed with wise mind
- **Distraction**: Various techniques based on context and preferences
- **Self-Soothing**: Sensory-based coping strategies
- **IMPROVE**: Imagery, Meaning, Prayer, Relaxation, One thing, Vacation, Encouragement

### Decision Tree Structure (from docs/wiki/dbt-distress-tolerance-tree.md)
1. **Crisis check** (intensity 8+ or keywords) ‚Üí Safety plan
2. **Situation assessment** (impulsive urges, emotional overwhelm, physical crisis, mixed)
3. **Context refinement** (time available, privacy, past successful skills)
4. **Specific skill recommendation** with context-aware coaching
5. **Post-skill assessment** and follow-up guidance

### Skill Personalization
- **DBT experience** assessment
- **Physical limitations** and accessibility needs
- **Environment considerations** (work, home, public)
- **Preference tracking** (movement vs. stillness, duration preferences)
- **Success tracking** for future recommendations

## Flet Testing Guidelines

### Testing Strategy for Flet Applications
- **Business Logic Separation**: Extract application logic into separate functions/classes that can be unit tested independently of Flet UI components
- **Unit Testing**: Test individual functions, event handlers, state management, data processing, and validation logic using pytest
- **Integration Testing**: Test component interactions, page navigation, state updates, and data flow between components
- **End-to-End Testing**: Use Playwright for browser automation and Flet accessibility testing
- **Test Structure**: Organize tests following pytest conventions with `test_*.py` naming and proper fixture usage

### E2E Testing with Playwright
- **Browser Automation**: Playwright provides reliable, modern browser automation for Flet applications
- **Flet Accessibility**: Enable Flet accessibility features to interact with DOM elements in CanvasKit-rendered apps
- **Multi-Viewport Testing**: Test responsive design across mobile, tablet, and desktop viewports
- **Performance Monitoring**: Capture page load times, console errors, and performance metrics
- **Visual Testing**: Automatic screenshot capture for debugging and visual regression testing
- **Async/Await Pattern**: Modern async Python patterns for better test performance and reliability

### Pytest Configuration
- Follow pytest conventions for Python test discovery
- Use fixtures for managing test dependencies and state
- Implement parametrization to avoid redundant test code
- Generate test coverage reports for quality assurance
- Integrate with GitHub Actions for continuous integration
- Use `pytest-asyncio` for async test support with Playwright

### Testing Best Practices
- Separate UI code from business logic for effective testing
- Test event handlers and state management functions independently
- Use mocking for external dependencies
- Maintain high test coverage for core application functionality
- Follow standard Python testing practices adapted for Flet applications
- **Playwright over Selenium**: Use Playwright for all browser automation (modern, faster, more reliable)

## Development Workflow and Automation

### Local Development Tools

The project includes comprehensive automation tools for consistent development experience:

#### Makefile Commands
Use `make` for all common development tasks:

```bash
# Essential workflow commands
make help           # Show all available commands
make install        # Install dependencies with uv
make setup-hooks    # Configure Git hooks (one-time setup)

# Development cycle
make dev            # Start development server (Flet web mode)
make dev-docker     # Start full stack with Docker Compose

# Code quality (run frequently)
make quick-check    # Fast validation (~10 seconds)
make format         # Auto-format code with black
make lint           # Check with ruff linter
make lint-fix       # Auto-fix linting issues

# Testing
make test-unit      # Unit tests only
make test-int       # Integration tests (requires Docker)
make test-e2e       # End-to-end browser tests (Playwright)
make coverage       # Test coverage report
make docker-test    # Test in Docker container

# Comprehensive validation
make validate       # Full validation before commits
make ci             # Simulate CI pipeline
```

#### Validation Scripts

**Quick Check** (`./scripts/quick-check.sh` or `make quick-check`):
- Fast feedback loop for active development (~10 seconds)
- Code formatting, basic linting, imports, essential tests
- Run frequently during development

**Full Validation** (`./scripts/validate.sh` or `make validate`):
- Comprehensive checks before committing (2-5 minutes)
- Code quality, security scanning, all test types, coverage analysis
- Matches CI pipeline requirements

**Environment Setup** (`./scripts/dev-setup.sh`):
- One-command setup for new developers
- Installs uv, configures environment, sets up Git hooks
- Validates setup and provides next steps

### Git Hooks Integration

Automated quality gates prevent issues from reaching the repository:

#### Pre-commit Hook
- **Trigger**: Before each `git commit`
- **Action**: Runs `quick-check.sh` for fast validation
- **Purpose**: Catch basic issues immediately
- **Bypass**: `git commit --no-verify` (use sparingly)

#### Pre-push Hook
- **Trigger**: Before `git push` to remote
- **Action**: Runs full validation (excluding E2E tests)
- **Purpose**: Ensure comprehensive quality before sharing code
- **Bypass**: `git push --no-verify` (use sparingly)

#### Commit Message Hook
- **Trigger**: During commit message creation
- **Action**: Validates conventional commit format
- **Required Format**: `type(scope): description`
- **Examples**:
  - `feat: add user authentication`
  - `fix(ui): resolve button alignment issue`
  - `docs: update installation guide`

### Recommended Development Workflow

#### 1. Initial Setup (One-time)
```bash
./scripts/dev-setup.sh     # Automated setup
# OR manually:
make install
make setup-hooks
cp .env.example .env       # Add your OPENAI_API_KEY
```

#### 2. Daily Development Cycle
```bash
# Start development
make dev                   # Flet development server
# OR
make dev-docker           # Full stack with PostgreSQL

# Make code changes...

# Quick validation (run frequently)
make quick-check          # ~10 seconds feedback

# Continue development...
```

#### 3. Before Committing
```bash
# Comprehensive validation
make validate             # 2-5 minutes, matches CI

# If validation passes:
git add .
git commit -m "feat: implement new feature"  # Hooks run automatically
```

#### 4. Before Pushing
```bash
# Optional: simulate CI pipeline
make ci

# Push (hooks run automatically)
git push origin feature-branch
```

### Docker Integration

All tools automatically detect Docker availability:

**With Docker Available**:
- Full integration tests with PostgreSQL
- Containerized unit test execution
- Docker build and test validation
- Complete CI pipeline simulation

**Docker Testing Features**:
- Optimized dependency caching for faster builds
- PostgreSQL client tools for database connectivity
- Unit tests run in isolated containers (91% coverage)
- Network-aware test configuration for service connectivity

**Without Docker**:
- Graceful degradation with warnings
- Unit tests and code quality checks still run
- Local-only validation mode

### Code Quality Standards

#### Automated Enforcement
- **Black**: Code formatting (zero configuration)
- **Ruff**: Fast Python linter with auto-fix
- **Safety**: Dependency vulnerability scanning
- **Bandit**: Security linting for common issues
- **Pytest**: Test execution with coverage reporting

#### Coverage Requirements
- **Minimum**: 80% line and branch coverage
- **Target**: 90% for business logic
- **Measurement**: Unit tests only (integration tests separate)
- **Reporting**: HTML and XML formats generated

#### Security Scanning
- **Dependency vulnerabilities**: `safety` check against known CVEs
- **Code security**: `bandit` static analysis for security anti-patterns
- **API key protection**: Automated detection of exposed secrets
- **CI integration**: Security scans run on every PR

### Troubleshooting Development Issues

#### Common Commands for Issue Resolution
```bash
# Fix formatting and linting
make format && make lint-fix

# Clean environment and rebuild
make clean && make install

# Test specific components
make test-unit              # Fast unit tests
uv run pytest tests/unit/test_config.py -v  # Specific test file

# Debug failed validation
./scripts/validate.sh --skip-e2e  # Skip slow E2E tests
```

#### Bypass Hooks When Needed
```bash
# Emergency commits (use sparingly)
git commit --no-verify -m "fix: urgent hotfix"
git push --no-verify
```

### Integration with IDE

The validation tools integrate with common IDEs:

- **VS Code**: Works with Python extension, pytest integration
- **PyCharm**: Compatible with built-in test runners and code inspection
- **Command Line**: Full functionality via terminal/shell

All tools use standard Python tooling conventions for maximum compatibility.

## Current CI/CD Status

### ‚úÖ All GitHub Actions Jobs Passing (6/6 Active)
- **Code Quality**: Black formatting, Ruff linting ‚úÖ
- **Unit Tests**: 39/40 unit tests passing ‚úÖ
- **Integration Tests**: Database and OpenAI API integration ‚úÖ
- **Security Scanning**: Safety, Bandit, CodeQL ‚úÖ
- **End-to-End Tests**: Playwright browser automation with Flet accessibility ‚úÖ
- **Docker Build & Test**: Containerized testing (re-enabled and working) ‚úÖ

### üéâ Recently Completed Improvements
1. **‚úÖ Docker Testing Infrastructure**: Fixed database connectivity, optimized builds, 91% test coverage
2. **‚úÖ Playwright Migration**: Replaced Selenium with modern Playwright for E2E tests
3. **‚úÖ Enhanced CI/CD Pipeline**: All jobs enabled and passing, improved reliability
4. **‚úÖ Browser Automation**: Async Playwright with multi-viewport and performance testing

### Local Development Status
- **91% test coverage** maintained ‚úÖ
- **100% code quality compliance** ‚úÖ
- **All core validations working** ‚úÖ
- **Git hooks functional** ‚úÖ
- **E2E tests with Playwright** ‚úÖ
- **Docker build and test working** ‚úÖ

### Testing Infrastructure Status
- ‚úÖ **Local Git Hooks**: Pre-commit and pre-push validation working
- ‚úÖ **Security Scanning**: No vulnerabilities found
- ‚úÖ **Code Quality**: 100% formatting and linting compliance
- ‚úÖ **Unit Test Coverage**: All core functionality tested
- ‚úÖ **Docker Testing**: Containerized tests with PostgreSQL integration
- ‚úÖ **Playwright E2E**: Modern browser automation with accessibility features